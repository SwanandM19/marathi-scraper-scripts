
# name: Daily News Scraper

# permissions:
#   contents: write

# on:
#   schedule:
#     # TEST: Runs at 3:20 PM IST (9:50 AM UTC)
#     - cron: '50 9 * * *'
    
#     # PRODUCTION: Runs at 6:00 PM IST (12:30 PM UTC)
#     - cron: '30 12 * * *'
  
#   workflow_dispatch:

# jobs:
#   scrape-news:
#     runs-on: ubuntu-latest
    
#     steps:
#       - name: Checkout repository
#         uses: actions/checkout@v4
      
#       - name: Set up Python 3.11
#         uses: actions/setup-python@v5
#         with:
#           python-version: '3.11'
      
#       - name: Install dependencies
#         run: |
#           python -m pip install --upgrade pip
#           pip install -r requirements.txt
      
#       # ðŸ†• ADD THIS STEP - Install Playwright browsers
#       - name: Install Playwright browsers
#         run: playwright install chromium
      
#       # ðŸ†• ADD THIS STEP - Install system dependencies for Chromium
#       - name: Install Playwright system dependencies
#         run: playwright install-deps chromium
      
#       - name: Run news scraper
#         env:
#           PERPLEXITY_API_KEY: ${{ secrets.PERPLEXITY_API_KEY }}
#         run: python scraper.py
      
#       - name: Create archives folder
#         run: mkdir -p archives
      
#       - name: Archive dated backup
#         run: |
#           if [ -f "latest_news.json" ]; then
#             cp latest_news.json "archives/news_$(date '+%Y%m%d_%H%M').json"
#           fi
      
#       - name: Keep only last 7 days in archives
#         run: |
#           find archives/ -name "news_*.json" -type f -mtime +7 -delete || true
      
#       - name: Commit and push results
#         run: |
#           git config --local user.email "github-actions[bot]@users.noreply.github.com"
#           git config --local user.name "github-actions[bot]"
#           git add -A
#           git diff --quiet && git diff --staged --quiet || git commit -m "ðŸ“° News update: $(date '+%Y-%m-%d %I:%M %p IST')"
#           git push



name: Daily News Scraper with Google Sheets

permissions:
  contents: write

on:
  schedule:
    # TEST: Runs at 3:50 PM IST (10:20 AM UTC)
    - cron: '20 10 * * *'
    
    # PRODUCTION: Runs at 6:00 PM IST (12:30 PM UTC)
    - cron: '30 12 * * *'
  
  workflow_dispatch:

jobs:
  scrape-news:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Set up Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      
      - name: Install Playwright browsers
        run: playwright install chromium
      
      - name: Install Playwright system dependencies
        run: playwright install-deps chromium
      
      # ðŸ†• NEW: Create Google credentials file from secret
      - name: Create Google Sheets credentials
        run: |
          echo '${{ secrets.GOOGLE_CREDENTIALS }}' > credentials.json
      
      - name: Run news scraper
        env:
          PERPLEXITY_API_KEY: ${{ secrets.PERPLEXITY_API_KEY }}
        run: python scraper.py
      
      # ðŸ†• OPTIONAL: Save backup JSON files (if you want local copies too)
      - name: Create archives folder
        run: mkdir -p archives
      
      - name: Archive run log
        run: |
          echo "Script completed at $(date '+%Y-%m-%d %H:%M:%S IST')" > "archives/run_$(date '+%Y%m%d_%H%M').log"
      
      - name: Keep only last 7 days in archives
        run: |
          find archives/ -name "run_*.log" -type f -mtime +7 -delete || true
      
      - name: Commit and push results
        run: |
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"
          git add -A
          git diff --quiet && git diff --staged --quiet || git commit -m "ðŸ“° Script run: $(date '+%Y-%m-%d %I:%M %p IST')"
          git push
